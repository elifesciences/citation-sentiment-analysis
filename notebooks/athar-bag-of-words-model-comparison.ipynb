{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from urllib.request import urlretrieve\n",
    "from zipfile import ZipFile\n",
    "from pathlib import Path\n",
    "\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, FunctionTransformer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics.scorer import check_scoring\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import imblearn.under_sampling\n",
    "import imblearn.over_sampling\n",
    "import imblearn.pipeline\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from citation_sentiment_analysis.datasets.athar import (\n",
    "    download_and_read_athar_txt_with_sentiment_label,\n",
    "    filter_long_sentences_from_athar\n",
    ")\n",
    "from citation_sentiment_analysis.datasets.words_en import download_and_read_english_words\n",
    "from citation_sentiment_analysis.preprocessing.token_filter import (\n",
    "    get_default_words_to_include,\n",
    "    keep_sentence_list_tokens_in,\n",
    "    get_token_counts,\n",
    "    drop_token_counts_not_in_top\n",
    ")\n",
    "from citation_sentiment_analysis.preprocessing.word_similarity import load_glove, most_similar\n",
    "from citation_sentiment_analysis.preprocessing.simple_text import simplify_tokens\n",
    "from citation_sentiment_analysis.utils.collection import iter_flatten\n",
    "from citation_sentiment_analysis.utils.jupyter import printmd\n",
    "from citation_sentiment_analysis.utils.pipeline import (\n",
    "    create_pipelines,\n",
    "    multi_pipeline_steps_cross_validate_scores\n",
    ")\n",
    "from citation_sentiment_analysis.utils.plot import bar_plot_with_numbers, configure_default_plot_style\n",
    "from citation_sentiment_analysis.utils.string import lower_all\n",
    "from citation_sentiment_analysis.utils.vectorizer import transform_to_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "configure_default_plot_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_paper_id</th>\n",
       "      <th>target_paper_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>citation_text</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1043</td>\n",
       "      <td>A00-2024</td>\n",
       "      <td>o</td>\n",
       "      <td>We analyzed a set of articles and identified s...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H05-1033</td>\n",
       "      <td>A00-2024</td>\n",
       "      <td>o</td>\n",
       "      <td>Table 3: Example compressions Compression AvgL...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I05-2009</td>\n",
       "      <td>A00-2024</td>\n",
       "      <td>o</td>\n",
       "      <td>5.3 Related works and discussion Our two-step ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I05-2009</td>\n",
       "      <td>A00-2024</td>\n",
       "      <td>o</td>\n",
       "      <td>(1999) proposed a summarization system based o...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I05-2009</td>\n",
       "      <td>A00-2024</td>\n",
       "      <td>o</td>\n",
       "      <td>We found that the deletion of lead parts did n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_paper_id target_paper_id sentiment  \\\n",
       "0        A00-1043        A00-2024         o   \n",
       "1        H05-1033        A00-2024         o   \n",
       "2        I05-2009        A00-2024         o   \n",
       "3        I05-2009        A00-2024         o   \n",
       "4        I05-2009        A00-2024         o   \n",
       "\n",
       "                                       citation_text sentiment_label  \n",
       "0  We analyzed a set of articles and identified s...         neutral  \n",
       "1  Table 3: Example compressions Compression AvgL...         neutral  \n",
       "2  5.3 Related works and discussion Our two-step ...         neutral  \n",
       "3  (1999) proposed a summarization system based o...         neutral  \n",
       "4  We found that the deletion of lead parts did n...         neutral  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "athar_df = filter_long_sentences_from_athar(download_and_read_athar_txt_with_sentiment_label())\n",
    "athar_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of word vectors: 400000 (embedding size: 50, sample tokens: ['the' ',' '.' 'of' 'to' 'and' 'in' 'a' '\"' \"'s\"])\n",
      "[('although', 0.9801390393473681), ('though', 0.9357160221673086), ('as', 0.9173495762573322), ('both', 0.9053673912921385), ('this', 0.905256886566932), ('but', 0.9050977636062989), ('be', 0.9030219190306548), ('also', 0.9024955114777448), ('latter', 0.8969175661233546), ('.', 0.8953238565845045)]\n"
     ]
    }
   ],
   "source": [
    "w2v = load_glove()\n",
    "print('number of word vectors: %d (embedding size: %d, sample tokens: %s)' % (\n",
    "    len(w2v), len(w2v.iloc[0]), w2v.index[:10].values\n",
    "))\n",
    "print(most_similar(w2v, 'however'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('although', 0.9801390393473681), ('though', 0.9357160221673086), ('as', 0.9173495762573322), ('both', 0.9053673912921385), ('this', 0.905256886566932), ('but', 0.9050977636062989), ('be', 0.9030219190306548), ('also', 0.9024955114777448), ('latter', 0.8969175661233546), ('.', 0.8953238565845045)]\n"
     ]
    }
   ],
   "source": [
    "print(most_similar(w2v, 'however'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109442"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_include = get_default_words_to_include()\n",
    "\n",
    "len(words_to_include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tokens: 384256, unique: 19323\n",
      "['We', 'analyzed', 'a', 'set', 'of', 'articles', 'and', 'identified', 'six', 'major', 'operations', 'that', 'can', 'be', 'used', 'for', 'editing', 'the', 'extracted', 'sentences']\n"
     ]
    }
   ],
   "source": [
    "citation_texts = athar_df['citation_text']\n",
    "# citation_texts = athar_balanced_df['citation_text']\n",
    "\n",
    "citation_tokens = [nltk.word_tokenize(s) for s in citation_texts]\n",
    "print('total tokens: %d, unique: %d' % (\n",
    "    sum(len(tokens) for tokens in citation_tokens),\n",
    "    len({t for tokens in citation_tokens for t in tokens})\n",
    "))\n",
    "print(citation_tokens[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tokens: 169508, unique: 6205\n",
      "['analyzed', 'set', 'articles', 'and', 'identified', 'six', 'major', 'operations', 'that', 'can', 'used', 'for', 'editing', 'the', 'extracted', 'sentences', 'including', 'removing', 'extraneous', 'phrases']\n"
     ]
    }
   ],
   "source": [
    "citation_filtered_tokens = keep_sentence_list_tokens_in(citation_tokens, words_to_include)\n",
    "print('total tokens: %d, unique: %d' % (\n",
    "    sum(len(tokens) for tokens in citation_filtered_tokens),\n",
    "    len({t for tokens in citation_filtered_tokens for t in tokens})\n",
    "))\n",
    "print(citation_filtered_tokens[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.317969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>238.447123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13249.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        description\n",
       "count   6205.000000\n",
       "mean      27.317969\n",
       "std      238.447123\n",
       "min        1.000000\n",
       "25%        1.000000\n",
       "50%        3.000000\n",
       "75%       12.000000\n",
       "max    13249.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prerequisite</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doubles</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doubly</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doubted</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>killed</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count\n",
       "token              \n",
       "prerequisite      1\n",
       "doubles           1\n",
       "doubly            1\n",
       "doubted           1\n",
       "killed            1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_token_counts = get_token_counts(iter_flatten(citation_filtered_tokens))\n",
    "display(filtered_token_counts.describe().to_frame('description'))\n",
    "display(filtered_token_counts.tail(5).to_frame('count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['recruiting']\n",
      "['however']\n",
      "['infinity']\n",
      "['following']\n",
      "['abstractors']\n"
     ]
    }
   ],
   "source": [
    "print(list(simplify_tokens(['recruit'], filtered_token_counts, w2v)))\n",
    "print(list(simplify_tokens(['however'], filtered_token_counts, w2v)))\n",
    "print(list(simplify_tokens(['xyz'], filtered_token_counts, w2v)))\n",
    "print(list(simplify_tokens(['subsequent'], filtered_token_counts, w2v)))\n",
    "print(list(simplify_tokens(['abstractors'], filtered_token_counts, w2v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6205                                                \n"
     ]
    }
   ],
   "source": [
    "simplified_token_map = {\n",
    "    token: simplified_token\n",
    "    for token, simplified_token in zip(\n",
    "        filtered_token_counts.index,\n",
    "        list(simplify_tokens(filtered_token_counts.index, filtered_token_counts, w2v, progress=True))\n",
    "    )\n",
    "}\n",
    "print(len(simplified_token_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tokens: 169508, unique: 1341\n",
      "['evaluated', 'set', 'articles', 'and', 'found', 'five', 'major', 'part', 'that', 'can', 'used', 'for', 'text', 'the', 'extracted', 'sentences', 'including', 'allow', 'correct', 'phrases']\n"
     ]
    }
   ],
   "source": [
    "citation_simplified_tokens = [\n",
    "    [simplified_token_map.get(t, t) for t in tokens]\n",
    "    for tokens in citation_filtered_tokens\n",
    "]\n",
    "print('total tokens: %d, unique: %d' % (\n",
    "    sum(len(tokens) for tokens in citation_simplified_tokens),\n",
    "    len({t for tokens in citation_simplified_tokens for t in tokens})\n",
    "))\n",
    "print(citation_simplified_tokens[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['analyz', 'set', 'articl', 'and', 'identifi', 'six', 'major', 'oper', 'that', 'can', 'use', 'for', 'edit', 'the', 'extract', 'sentenc', 'includ', 'remov', 'extran', 'phrase']\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "citation_stemmed_tokens = [[ps.stem(t) for t in tokens] for tokens in citation_filtered_tokens]\n",
    "print(citation_stemmed_tokens[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['evalu', 'set', 'articl', 'and', 'found', 'five', 'major', 'part', 'that', 'can', 'use', 'for', 'text', 'the', 'extract', 'sentenc', 'includ', 'allow', 'correct', 'phrase']\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "citation_simplified_stemmed_tokens = [[ps.stem(t) for t in tokens] for tokens in citation_simplified_tokens]\n",
    "print(citation_simplified_stemmed_tokens[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>3617.0</td>\n",
       "      <td>46.864252</td>\n",
       "      <td>322.632801</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13249.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count       mean         std  min  25%  50%   75%      max\n",
       "description  3617.0  46.864252  322.632801  1.0  1.0  5.0  21.0  13249.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>token</th>\n",
       "      <th>the</th>\n",
       "      <th>and</th>\n",
       "      <th>use</th>\n",
       "      <th>for</th>\n",
       "      <th>model</th>\n",
       "      <th>word</th>\n",
       "      <th>that</th>\n",
       "      <th>with</th>\n",
       "      <th>translat</th>\n",
       "      <th>are</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>most frequent</th>\n",
       "      <td>13249</td>\n",
       "      <td>10966</td>\n",
       "      <td>3511</td>\n",
       "      <td>3313</td>\n",
       "      <td>2965</td>\n",
       "      <td>1964</td>\n",
       "      <td>1739</td>\n",
       "      <td>1679</td>\n",
       "      <td>1661</td>\n",
       "      <td>1538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "token            the    and   use   for  model  word  that  with  translat  \\\n",
       "most frequent  13249  10966  3511  3313   2965  1964  1739  1679      1661   \n",
       "\n",
       "token           are  \n",
       "most frequent  1538  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>token</th>\n",
       "      <th>sport</th>\n",
       "      <th>malform</th>\n",
       "      <th>dollar</th>\n",
       "      <th>speedi</th>\n",
       "      <th>spectrum</th>\n",
       "      <th>malais</th>\n",
       "      <th>spearman</th>\n",
       "      <th>spear</th>\n",
       "      <th>mal</th>\n",
       "      <th>era</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>least frequent</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "token           sport  malform  dollar  speedi  spectrum  malais  spearman  \\\n",
       "least frequent      1        1       1       1         1       1         1   \n",
       "\n",
       "token           spear  mal  era  \n",
       "least frequent      1    1    1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>token</th>\n",
       "      <th>evert</th>\n",
       "      <th>dia</th>\n",
       "      <th>cat</th>\n",
       "      <th>prefix</th>\n",
       "      <th>dimension</th>\n",
       "      <th>brook</th>\n",
       "      <th>oppos</th>\n",
       "      <th>hereaft</th>\n",
       "      <th>hall</th>\n",
       "      <th>sigmoid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>less than 10</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "token         evert  dia  cat  prefix  dimension  brook  oppos  hereaft  hall  \\\n",
       "less than 10      9    9    9       9          9      9      9        9     9   \n",
       "\n",
       "token         sigmoid  \n",
       "less than 10        9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of tokens: 3617\n",
      "number of tokens only appearing once: 928\n",
      "number of tokens appearing less than 10 times: 2282\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_token_count_stats(token_counts):\n",
    "    display(token_counts.describe().to_frame('description').T)\n",
    "    display(token_counts.head(10).to_frame('most frequent').T)\n",
    "    display(token_counts.tail(10).to_frame('least frequent').T)\n",
    "    display(token_counts[token_counts < 10].head(10).to_frame('less than 10').T)\n",
    "    print('total number of tokens:', len(token_counts))\n",
    "    print('number of tokens only appearing once:', sum(token_counts == 1))\n",
    "    print('number of tokens appearing less than 10 times:', sum(token_counts < 10))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    token_counts.hist(ax=ax, bins=100, bottom=0.1)\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "token_counts = get_token_counts(iter_flatten(citation_stemmed_tokens))\n",
    "show_token_count_stats(token_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "token_counts[token_counts < 1000].hist(ax=ax, bins=100, bottom=0.1)\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>1042.0</td>\n",
       "      <td>162.675624</td>\n",
       "      <td>594.772952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>13249.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count        mean         std  min  25%   50%    75%      max\n",
       "description  1042.0  162.675624  594.772952  1.0  3.0  62.0  162.0  13249.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>token</th>\n",
       "      <th>the</th>\n",
       "      <th>and</th>\n",
       "      <th>use</th>\n",
       "      <th>for</th>\n",
       "      <th>model</th>\n",
       "      <th>word</th>\n",
       "      <th>that</th>\n",
       "      <th>translat</th>\n",
       "      <th>with</th>\n",
       "      <th>are</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>most frequent</th>\n",
       "      <td>13249</td>\n",
       "      <td>10993</td>\n",
       "      <td>3682</td>\n",
       "      <td>3339</td>\n",
       "      <td>3083</td>\n",
       "      <td>2006</td>\n",
       "      <td>1739</td>\n",
       "      <td>1687</td>\n",
       "      <td>1679</td>\n",
       "      <td>1538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "token            the    and   use   for  model  word  that  translat  with  \\\n",
       "most frequent  13249  10993  3682  3339   3083  2006  1739      1687  1679   \n",
       "\n",
       "token           are  \n",
       "most frequent  1538  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>token</th>\n",
       "      <th>pipag</th>\n",
       "      <th>pipe</th>\n",
       "      <th>pirat</th>\n",
       "      <th>pli</th>\n",
       "      <th>poller</th>\n",
       "      <th>porter</th>\n",
       "      <th>constel</th>\n",
       "      <th>poss</th>\n",
       "      <th>consecut</th>\n",
       "      <th>zen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>least frequent</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "token           pipag  pipe  pirat  pli  poller  porter  constel  poss  \\\n",
       "least frequent      1     1      1    1       1       1        1     1   \n",
       "\n",
       "token           consecut  zen  \n",
       "least frequent         1    1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>token</th>\n",
       "      <th>evert</th>\n",
       "      <th>appendix</th>\n",
       "      <th>abduct</th>\n",
       "      <th>pyramid</th>\n",
       "      <th>quat</th>\n",
       "      <th>rasp</th>\n",
       "      <th>synonymi</th>\n",
       "      <th>hereaft</th>\n",
       "      <th>lex</th>\n",
       "      <th>converg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>less than 10</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "token         evert  appendix  abduct  pyramid  quat  rasp  synonymi  hereaft  \\\n",
       "less than 10      9         9       9        9     9     9         9        9   \n",
       "\n",
       "token         lex  converg  \n",
       "less than 10    8        8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of tokens: 1042\n",
      "number of tokens only appearing once: 181\n",
      "number of tokens appearing less than 10 times: 345\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simplified_token_counts = get_token_counts(iter_flatten(citation_simplified_stemmed_tokens))\n",
    "show_token_count_stats(simplified_token_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8699, 3617)\n",
      "(8699,)\n"
     ]
    }
   ],
   "source": [
    "X_all = transform_to_counts(citation_stemmed_tokens)\n",
    "y_all = athar_df['sentiment'] == 'n'\n",
    "\n",
    "print(X_all.shape)\n",
    "print(y_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc mean: 0.770593509736653, std: 0.0432709152384011\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(\n",
    "    BernoulliNB(), X_all, y_all, cv=4, scoring='roc_auc'\n",
    ")\n",
    "print('roc_auc mean: %s, std: %s' % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9513108614232211"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_all, y_all)\n",
    "f1_score(y_all, model.predict(X_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_samplers = [\n",
    "    imblearn.over_sampling.RandomOverSampler(random_state=42),\n",
    "    imblearn.under_sampling.RandomUnderSampler(random_state=42),\n",
    "]\n",
    "\n",
    "default_models = [\n",
    "    BernoulliNB(),\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    RandomForestClassifier(random_state=42),\n",
    "]\n",
    "\n",
    "default_pipelines = create_pipelines([\n",
    "    ('sampler', default_samplers),\n",
    "    ('model', default_models)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Generally filtered tokens"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "X (8699, 3617) -> y (8699,)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sampler</th>\n",
       "      <th>model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.798022</td>\n",
       "      <td>0.009733</td>\n",
       "      <td>0.186017</td>\n",
       "      <td>0.023907</td>\n",
       "      <td>0.106910</td>\n",
       "      <td>0.014694</td>\n",
       "      <td>0.720986</td>\n",
       "      <td>0.079838</td>\n",
       "      <td>0.824288</td>\n",
       "      <td>0.020029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.803425</td>\n",
       "      <td>0.033205</td>\n",
       "      <td>0.163542</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>0.095508</td>\n",
       "      <td>0.020272</td>\n",
       "      <td>0.588616</td>\n",
       "      <td>0.047324</td>\n",
       "      <td>0.784089</td>\n",
       "      <td>0.019967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.922290</td>\n",
       "      <td>0.007719</td>\n",
       "      <td>0.263766</td>\n",
       "      <td>0.018087</td>\n",
       "      <td>0.191972</td>\n",
       "      <td>0.026684</td>\n",
       "      <td>0.436356</td>\n",
       "      <td>0.059194</td>\n",
       "      <td>0.772878</td>\n",
       "      <td>0.019128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.965973</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.094665</td>\n",
       "      <td>0.033336</td>\n",
       "      <td>0.325874</td>\n",
       "      <td>0.119525</td>\n",
       "      <td>0.055540</td>\n",
       "      <td>0.019516</td>\n",
       "      <td>0.761414</td>\n",
       "      <td>0.004964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.727668</td>\n",
       "      <td>0.016126</td>\n",
       "      <td>0.146738</td>\n",
       "      <td>0.016373</td>\n",
       "      <td>0.081644</td>\n",
       "      <td>0.009640</td>\n",
       "      <td>0.733908</td>\n",
       "      <td>0.099518</td>\n",
       "      <td>0.730825</td>\n",
       "      <td>0.041008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.924474</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.194466</td>\n",
       "      <td>0.016241</td>\n",
       "      <td>0.150431</td>\n",
       "      <td>0.024687</td>\n",
       "      <td>0.284589</td>\n",
       "      <td>0.029595</td>\n",
       "      <td>0.615197</td>\n",
       "      <td>0.009309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sampler                   model  accuracy                  f1  \\\n",
       "                                                   mean       std      mean   \n",
       "3  RandomUnderSampler             BernoulliNB  0.798022  0.009733  0.186017   \n",
       "5  RandomUnderSampler  RandomForestClassifier  0.803425  0.033205  0.163542   \n",
       "0   RandomOverSampler             BernoulliNB  0.922290  0.007719  0.263766   \n",
       "2   RandomOverSampler  RandomForestClassifier  0.965973  0.003259  0.094665   \n",
       "4  RandomUnderSampler  DecisionTreeClassifier  0.727668  0.016126  0.146738   \n",
       "1   RandomOverSampler  DecisionTreeClassifier  0.924474  0.007744  0.194466   \n",
       "\n",
       "            precision              recall             roc_auc            \n",
       "        std      mean       std      mean       std      mean       std  \n",
       "3  0.023907  0.106910  0.014694  0.720986  0.079838  0.824288  0.020029  \n",
       "5  0.030584  0.095508  0.020272  0.588616  0.047324  0.784089  0.019967  \n",
       "0  0.018087  0.191972  0.026684  0.436356  0.059194  0.772878  0.019128  \n",
       "2  0.033336  0.325874  0.119525  0.055540  0.019516  0.761414  0.004964  \n",
       "4  0.016373  0.081644  0.009640  0.733908  0.099518  0.730825  0.041008  \n",
       "1  0.016241  0.150431  0.024687  0.284589  0.029595  0.615197  0.009309  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printmd('## Generally filtered tokens')\n",
    "multi_pipeline_steps_cross_validate_scores(\n",
    "    default_pipelines,\n",
    "    transform_to_counts(citation_stemmed_tokens), y_all,\n",
    "    cv=KFold(n_splits=4, shuffle=True, random_state=42),\n",
    "    scoring=('roc_auc', 'accuracy', 'f1', 'precision', 'recall')\n",
    ").groupby(['sampler', 'model']).agg(['mean', 'std']).reset_index().sort_values(\n",
    "    ('roc_auc', 'mean'), ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Top 100 tokens"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "X (8699, 100) -> y (8699,)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sampler</th>\n",
       "      <th>model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.749396</td>\n",
       "      <td>0.012194</td>\n",
       "      <td>0.143024</td>\n",
       "      <td>0.016577</td>\n",
       "      <td>0.080482</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.652414</td>\n",
       "      <td>0.054347</td>\n",
       "      <td>0.758290</td>\n",
       "      <td>0.016418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.682147</td>\n",
       "      <td>0.020601</td>\n",
       "      <td>0.120707</td>\n",
       "      <td>0.013057</td>\n",
       "      <td>0.066340</td>\n",
       "      <td>0.007885</td>\n",
       "      <td>0.681971</td>\n",
       "      <td>0.074661</td>\n",
       "      <td>0.740386</td>\n",
       "      <td>0.030338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.679391</td>\n",
       "      <td>0.020810</td>\n",
       "      <td>0.117464</td>\n",
       "      <td>0.018011</td>\n",
       "      <td>0.064592</td>\n",
       "      <td>0.011020</td>\n",
       "      <td>0.662326</td>\n",
       "      <td>0.038632</td>\n",
       "      <td>0.712363</td>\n",
       "      <td>0.026893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.961834</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.061958</td>\n",
       "      <td>0.008407</td>\n",
       "      <td>0.174053</td>\n",
       "      <td>0.092665</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.648997</td>\n",
       "      <td>0.021711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.603517</td>\n",
       "      <td>0.034377</td>\n",
       "      <td>0.098490</td>\n",
       "      <td>0.010430</td>\n",
       "      <td>0.053188</td>\n",
       "      <td>0.006056</td>\n",
       "      <td>0.677630</td>\n",
       "      <td>0.086998</td>\n",
       "      <td>0.636568</td>\n",
       "      <td>0.027102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.928497</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>0.103496</td>\n",
       "      <td>0.035180</td>\n",
       "      <td>0.087843</td>\n",
       "      <td>0.030821</td>\n",
       "      <td>0.127812</td>\n",
       "      <td>0.043218</td>\n",
       "      <td>0.539748</td>\n",
       "      <td>0.024735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sampler                   model  accuracy                  f1  \\\n",
       "                                                   mean       std      mean   \n",
       "0   RandomOverSampler             BernoulliNB  0.749396  0.012194  0.143024   \n",
       "3  RandomUnderSampler             BernoulliNB  0.682147  0.020601  0.120707   \n",
       "5  RandomUnderSampler  RandomForestClassifier  0.679391  0.020810  0.117464   \n",
       "2   RandomOverSampler  RandomForestClassifier  0.961834  0.003958  0.061958   \n",
       "4  RandomUnderSampler  DecisionTreeClassifier  0.603517  0.034377  0.098490   \n",
       "1   RandomOverSampler  DecisionTreeClassifier  0.928497  0.005987  0.103496   \n",
       "\n",
       "            precision              recall             roc_auc            \n",
       "        std      mean       std      mean       std      mean       std  \n",
       "0  0.016577  0.080482  0.010417  0.652414  0.054347  0.758290  0.016418  \n",
       "3  0.013057  0.066340  0.007885  0.681971  0.074661  0.740386  0.030338  \n",
       "5  0.018011  0.064592  0.011020  0.662326  0.038632  0.712363  0.026893  \n",
       "2  0.008407  0.174053  0.092665  0.039254  0.005000  0.648997  0.021711  \n",
       "4  0.010430  0.053188  0.006056  0.677630  0.086998  0.636568  0.027102  \n",
       "1  0.035180  0.087843  0.030821  0.127812  0.043218  0.539748  0.024735  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printmd('## Top 100 tokens')\n",
    "multi_pipeline_steps_cross_validate_scores(\n",
    "    default_pipelines,\n",
    "    drop_token_counts_not_in_top(transform_to_counts(\n",
    "        citation_stemmed_tokens\n",
    "    ), 100), y_all,\n",
    "    cv=KFold(n_splits=4, shuffle=True, random_state=42),\n",
    "    scoring=('roc_auc', 'accuracy', 'f1', 'precision', 'recall')\n",
    ").groupby(['sampler', 'model']).agg(['mean', 'std']).reset_index().sort_values(\n",
    "    ('roc_auc', 'mean'), ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Simplified tokens"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "X (8699, 1042) -> y (8699,)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sampler</th>\n",
       "      <th>model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.759511</td>\n",
       "      <td>0.017811</td>\n",
       "      <td>0.162342</td>\n",
       "      <td>0.022696</td>\n",
       "      <td>0.091529</td>\n",
       "      <td>0.013823</td>\n",
       "      <td>0.724905</td>\n",
       "      <td>0.065173</td>\n",
       "      <td>0.821032</td>\n",
       "      <td>0.026977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.878722</td>\n",
       "      <td>0.011301</td>\n",
       "      <td>0.224094</td>\n",
       "      <td>0.035609</td>\n",
       "      <td>0.141924</td>\n",
       "      <td>0.026643</td>\n",
       "      <td>0.546805</td>\n",
       "      <td>0.089887</td>\n",
       "      <td>0.805516</td>\n",
       "      <td>0.013714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.761809</td>\n",
       "      <td>0.027392</td>\n",
       "      <td>0.153122</td>\n",
       "      <td>0.012354</td>\n",
       "      <td>0.086603</td>\n",
       "      <td>0.007710</td>\n",
       "      <td>0.676163</td>\n",
       "      <td>0.115424</td>\n",
       "      <td>0.799807</td>\n",
       "      <td>0.031439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.964938</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>0.098638</td>\n",
       "      <td>0.042229</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.169558</td>\n",
       "      <td>0.059566</td>\n",
       "      <td>0.024704</td>\n",
       "      <td>0.758906</td>\n",
       "      <td>0.041107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.687545</td>\n",
       "      <td>0.032738</td>\n",
       "      <td>0.132735</td>\n",
       "      <td>0.007328</td>\n",
       "      <td>0.072913</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>0.746299</td>\n",
       "      <td>0.059366</td>\n",
       "      <td>0.715964</td>\n",
       "      <td>0.031260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.928612</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.174619</td>\n",
       "      <td>0.017586</td>\n",
       "      <td>0.139863</td>\n",
       "      <td>0.020577</td>\n",
       "      <td>0.236300</td>\n",
       "      <td>0.024825</td>\n",
       "      <td>0.594096</td>\n",
       "      <td>0.010429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sampler                   model  accuracy                  f1  \\\n",
       "                                                   mean       std      mean   \n",
       "3  RandomUnderSampler             BernoulliNB  0.759511  0.017811  0.162342   \n",
       "0   RandomOverSampler             BernoulliNB  0.878722  0.011301  0.224094   \n",
       "5  RandomUnderSampler  RandomForestClassifier  0.761809  0.027392  0.153122   \n",
       "2   RandomOverSampler  RandomForestClassifier  0.964938  0.003064  0.098638   \n",
       "4  RandomUnderSampler  DecisionTreeClassifier  0.687545  0.032738  0.132735   \n",
       "1   RandomOverSampler  DecisionTreeClassifier  0.928612  0.003773  0.174619   \n",
       "\n",
       "            precision              recall             roc_auc            \n",
       "        std      mean       std      mean       std      mean       std  \n",
       "3  0.022696  0.091529  0.013823  0.724905  0.065173  0.821032  0.026977  \n",
       "0  0.035609  0.141924  0.026643  0.546805  0.089887  0.805516  0.013714  \n",
       "5  0.012354  0.086603  0.007710  0.676163  0.115424  0.799807  0.031439  \n",
       "2  0.042229  0.300000  0.169558  0.059566  0.024704  0.758906  0.041107  \n",
       "4  0.007328  0.072913  0.004610  0.746299  0.059366  0.715964  0.031260  \n",
       "1  0.017586  0.139863  0.020577  0.236300  0.024825  0.594096  0.010429  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printmd('## Simplified tokens')\n",
    "multi_pipeline_steps_cross_validate_scores(\n",
    "    default_pipelines,\n",
    "    transform_to_counts(citation_simplified_stemmed_tokens), y_all,\n",
    "    cv=KFold(n_splits=4, shuffle=True, random_state=42),\n",
    "    scoring=('roc_auc', 'accuracy', 'f1', 'precision', 'recall')\n",
    ").groupby(['sampler', 'model']).agg(['mean', 'std']).reset_index().sort_values(\n",
    "    ('roc_auc', 'mean'), ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Top 100 simplified tokens"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "X (8699, 100) -> y (8699,)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sampler</th>\n",
       "      <th>model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.749166</td>\n",
       "      <td>0.008814</td>\n",
       "      <td>0.137942</td>\n",
       "      <td>0.020146</td>\n",
       "      <td>0.077657</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>0.625101</td>\n",
       "      <td>0.059425</td>\n",
       "      <td>0.765077</td>\n",
       "      <td>0.015423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.687663</td>\n",
       "      <td>0.017573</td>\n",
       "      <td>0.119992</td>\n",
       "      <td>0.014428</td>\n",
       "      <td>0.066032</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.664464</td>\n",
       "      <td>0.061817</td>\n",
       "      <td>0.750865</td>\n",
       "      <td>0.032419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.682605</td>\n",
       "      <td>0.027250</td>\n",
       "      <td>0.119861</td>\n",
       "      <td>0.016828</td>\n",
       "      <td>0.065859</td>\n",
       "      <td>0.009823</td>\n",
       "      <td>0.671258</td>\n",
       "      <td>0.048423</td>\n",
       "      <td>0.720261</td>\n",
       "      <td>0.025113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.962639</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.074318</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.194378</td>\n",
       "      <td>0.060817</td>\n",
       "      <td>0.047168</td>\n",
       "      <td>0.009823</td>\n",
       "      <td>0.647325</td>\n",
       "      <td>0.036498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.600758</td>\n",
       "      <td>0.028625</td>\n",
       "      <td>0.087355</td>\n",
       "      <td>0.023646</td>\n",
       "      <td>0.047242</td>\n",
       "      <td>0.013196</td>\n",
       "      <td>0.586623</td>\n",
       "      <td>0.096523</td>\n",
       "      <td>0.592585</td>\n",
       "      <td>0.046114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.928612</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>0.118403</td>\n",
       "      <td>0.018103</td>\n",
       "      <td>0.098699</td>\n",
       "      <td>0.019144</td>\n",
       "      <td>0.149212</td>\n",
       "      <td>0.016538</td>\n",
       "      <td>0.551805</td>\n",
       "      <td>0.007862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sampler                   model  accuracy                  f1  \\\n",
       "                                                   mean       std      mean   \n",
       "0   RandomOverSampler             BernoulliNB  0.749166  0.008814  0.137942   \n",
       "3  RandomUnderSampler             BernoulliNB  0.687663  0.017573  0.119992   \n",
       "5  RandomUnderSampler  RandomForestClassifier  0.682605  0.027250  0.119861   \n",
       "2   RandomOverSampler  RandomForestClassifier  0.962639  0.002564  0.074318   \n",
       "4  RandomUnderSampler  DecisionTreeClassifier  0.600758  0.028625  0.087355   \n",
       "1   RandomOverSampler  DecisionTreeClassifier  0.928612  0.005085  0.118403   \n",
       "\n",
       "            precision              recall             roc_auc            \n",
       "        std      mean       std      mean       std      mean       std  \n",
       "0  0.020146  0.077657  0.012270  0.625101  0.059425  0.765077  0.015423  \n",
       "3  0.014428  0.066032  0.008498  0.664464  0.061817  0.750865  0.032419  \n",
       "5  0.016828  0.065859  0.009823  0.671258  0.048423  0.720261  0.025113  \n",
       "2  0.012500  0.194378  0.060817  0.047168  0.009823  0.647325  0.036498  \n",
       "4  0.023646  0.047242  0.013196  0.586623  0.096523  0.592585  0.046114  \n",
       "1  0.018103  0.098699  0.019144  0.149212  0.016538  0.551805  0.007862  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printmd('## Top 100 simplified tokens')\n",
    "multi_pipeline_steps_cross_validate_scores(\n",
    "    default_pipelines,\n",
    "    drop_token_counts_not_in_top(transform_to_counts(\n",
    "        citation_simplified_stemmed_tokens\n",
    "    ), 100), y_all,\n",
    "    cv=KFold(n_splits=4, shuffle=True, random_state=42),\n",
    "    scoring=('roc_auc', 'accuracy', 'f1', 'precision', 'recall')\n",
    ").groupby(['sampler', 'model']).agg(['mean', 'std']).reset_index().sort_values(\n",
    "    ('roc_auc', 'mean'), ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Top 100 simplified tokens (not stemmed)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "X (8699, 100) -> y (8699,)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sampler</th>\n",
       "      <th>model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.771353</td>\n",
       "      <td>0.013045</td>\n",
       "      <td>0.151838</td>\n",
       "      <td>0.030162</td>\n",
       "      <td>0.086454</td>\n",
       "      <td>0.018472</td>\n",
       "      <td>0.635153</td>\n",
       "      <td>0.085004</td>\n",
       "      <td>0.764550</td>\n",
       "      <td>0.024135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.727899</td>\n",
       "      <td>0.012197</td>\n",
       "      <td>0.138796</td>\n",
       "      <td>0.019128</td>\n",
       "      <td>0.077374</td>\n",
       "      <td>0.011508</td>\n",
       "      <td>0.684878</td>\n",
       "      <td>0.082602</td>\n",
       "      <td>0.757114</td>\n",
       "      <td>0.047379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.689274</td>\n",
       "      <td>0.018019</td>\n",
       "      <td>0.119648</td>\n",
       "      <td>0.016595</td>\n",
       "      <td>0.065920</td>\n",
       "      <td>0.009799</td>\n",
       "      <td>0.658435</td>\n",
       "      <td>0.071850</td>\n",
       "      <td>0.733126</td>\n",
       "      <td>0.047011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.959535</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.066198</td>\n",
       "      <td>0.030362</td>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.096919</td>\n",
       "      <td>0.044613</td>\n",
       "      <td>0.019721</td>\n",
       "      <td>0.681172</td>\n",
       "      <td>0.010713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.593972</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>0.091219</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.049158</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>0.636344</td>\n",
       "      <td>0.037906</td>\n",
       "      <td>0.609464</td>\n",
       "      <td>0.017980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.931832</td>\n",
       "      <td>0.004087</td>\n",
       "      <td>0.121791</td>\n",
       "      <td>0.026075</td>\n",
       "      <td>0.107451</td>\n",
       "      <td>0.036342</td>\n",
       "      <td>0.146969</td>\n",
       "      <td>0.025660</td>\n",
       "      <td>0.551154</td>\n",
       "      <td>0.012377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sampler                   model  accuracy                  f1  \\\n",
       "                                                   mean       std      mean   \n",
       "0   RandomOverSampler             BernoulliNB  0.771353  0.013045  0.151838   \n",
       "3  RandomUnderSampler             BernoulliNB  0.727899  0.012197  0.138796   \n",
       "5  RandomUnderSampler  RandomForestClassifier  0.689274  0.018019  0.119648   \n",
       "2   RandomOverSampler  RandomForestClassifier  0.959535  0.005135  0.066198   \n",
       "4  RandomUnderSampler  DecisionTreeClassifier  0.593972  0.023148  0.091219   \n",
       "1   RandomOverSampler  DecisionTreeClassifier  0.931832  0.004087  0.121791   \n",
       "\n",
       "            precision              recall             roc_auc            \n",
       "        std      mean       std      mean       std      mean       std  \n",
       "0  0.030162  0.086454  0.018472  0.635153  0.085004  0.764550  0.024135  \n",
       "3  0.019128  0.077374  0.011508  0.684878  0.082602  0.757114  0.047379  \n",
       "5  0.016595  0.065920  0.009799  0.658435  0.071850  0.733126  0.047011  \n",
       "2  0.030362  0.143317  0.096919  0.044613  0.019721  0.681172  0.010713  \n",
       "4  0.007481  0.049158  0.004316  0.636344  0.037906  0.609464  0.017980  \n",
       "1  0.026075  0.107451  0.036342  0.146969  0.025660  0.551154  0.012377  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printmd('## Top 100 simplified tokens (not stemmed)')\n",
    "multi_pipeline_steps_cross_validate_scores(\n",
    "    default_pipelines,\n",
    "    drop_token_counts_not_in_top(transform_to_counts(\n",
    "        citation_simplified_tokens\n",
    "    ), 100), y_all,\n",
    "    cv=KFold(n_splits=4, shuffle=True, random_state=42),\n",
    "    scoring=('roc_auc', 'accuracy', 'f1', 'precision', 'recall')\n",
    ").groupby(['sampler', 'model']).agg(['mean', 'std']).reset_index().sort_values(\n",
    "    ('roc_auc', 'mean'), ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Top 100 simplified tokens (SVC)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "X (8699, 100) -> y (8699,)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sampler</th>\n",
       "      <th>model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.810897</td>\n",
       "      <td>0.007852</td>\n",
       "      <td>0.160991</td>\n",
       "      <td>0.022124</td>\n",
       "      <td>0.094039</td>\n",
       "      <td>0.014167</td>\n",
       "      <td>0.567218</td>\n",
       "      <td>0.074133</td>\n",
       "      <td>0.767412</td>\n",
       "      <td>0.016655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.749166</td>\n",
       "      <td>0.008814</td>\n",
       "      <td>0.137942</td>\n",
       "      <td>0.020146</td>\n",
       "      <td>0.077657</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>0.625101</td>\n",
       "      <td>0.059425</td>\n",
       "      <td>0.765077</td>\n",
       "      <td>0.015423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.687663</td>\n",
       "      <td>0.017573</td>\n",
       "      <td>0.119992</td>\n",
       "      <td>0.014428</td>\n",
       "      <td>0.066032</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.664464</td>\n",
       "      <td>0.061817</td>\n",
       "      <td>0.750865</td>\n",
       "      <td>0.032419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.712493</td>\n",
       "      <td>0.041683</td>\n",
       "      <td>0.116173</td>\n",
       "      <td>0.017459</td>\n",
       "      <td>0.064686</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.584275</td>\n",
       "      <td>0.063375</td>\n",
       "      <td>0.719279</td>\n",
       "      <td>0.019105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.600758</td>\n",
       "      <td>0.028625</td>\n",
       "      <td>0.087355</td>\n",
       "      <td>0.023646</td>\n",
       "      <td>0.047242</td>\n",
       "      <td>0.013196</td>\n",
       "      <td>0.586623</td>\n",
       "      <td>0.096523</td>\n",
       "      <td>0.592585</td>\n",
       "      <td>0.046114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.928612</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>0.118403</td>\n",
       "      <td>0.018103</td>\n",
       "      <td>0.098699</td>\n",
       "      <td>0.019144</td>\n",
       "      <td>0.149212</td>\n",
       "      <td>0.016538</td>\n",
       "      <td>0.551805</td>\n",
       "      <td>0.007862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sampler                   model  accuracy                  f1  \\\n",
       "                                                   mean       std      mean   \n",
       "2   RandomOverSampler                     SVC  0.810897  0.007852  0.160991   \n",
       "0   RandomOverSampler             BernoulliNB  0.749166  0.008814  0.137942   \n",
       "3  RandomUnderSampler             BernoulliNB  0.687663  0.017573  0.119992   \n",
       "5  RandomUnderSampler                     SVC  0.712493  0.041683  0.116173   \n",
       "4  RandomUnderSampler  DecisionTreeClassifier  0.600758  0.028625  0.087355   \n",
       "1   RandomOverSampler  DecisionTreeClassifier  0.928612  0.005085  0.118403   \n",
       "\n",
       "            precision              recall             roc_auc            \n",
       "        std      mean       std      mean       std      mean       std  \n",
       "2  0.022124  0.094039  0.014167  0.567218  0.074133  0.767412  0.016655  \n",
       "0  0.020146  0.077657  0.012270  0.625101  0.059425  0.765077  0.015423  \n",
       "3  0.014428  0.066032  0.008498  0.664464  0.061817  0.750865  0.032419  \n",
       "5  0.017459  0.064686  0.010538  0.584275  0.063375  0.719279  0.019105  \n",
       "4  0.023646  0.047242  0.013196  0.586623  0.096523  0.592585  0.046114  \n",
       "1  0.018103  0.098699  0.019144  0.149212  0.016538  0.551805  0.007862  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printmd('## Top 100 simplified tokens (SVC)')\n",
    "multi_pipeline_steps_cross_validate_scores(\n",
    "    create_pipelines([\n",
    "        ('sampler', default_samplers),\n",
    "        ('model', [\n",
    "            BernoulliNB(),\n",
    "            DecisionTreeClassifier(random_state=42),\n",
    "            SVC(random_state=42),\n",
    "        ])\n",
    "    ]),\n",
    "    drop_token_counts_not_in_top(transform_to_counts(\n",
    "        citation_simplified_stemmed_tokens\n",
    "    ), 100), y_all,\n",
    "    cv=KFold(n_splits=4, shuffle=True, random_state=42),\n",
    "    scoring=('roc_auc', 'accuracy', 'f1', 'precision', 'recall')\n",
    ").groupby(['sampler', 'model']).agg(['mean', 'std']).reset_index().sort_values(\n",
    "    ('roc_auc', 'mean'), ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Longer than **100** tokens: **358**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Longer than **1000** tokens: **0**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num tokens</th>\n",
       "      <td>8699.0</td>\n",
       "      <td>44.172434</td>\n",
       "      <td>26.031167</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>286.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count       mean        std  min   25%   50%   75%    max\n",
       "num tokens  8699.0  44.172434  26.031167  4.0  28.0  38.0  53.0  286.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_lengths = pd.Series([len(s) for s in citation_tokens])\n",
    "printmd('Longer than **100** tokens: **%s**' % sum(sequence_lengths > 100))\n",
    "printmd('Longer than **1000** tokens: **%s**' % sum(sequence_lengths > 1000))\n",
    "sequence_lengths.describe().to_frame('num tokens').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7819548872180451"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_sampled, y_sampled = imblearn.under_sampling.RandomUnderSampler().fit_sample(\n",
    "#     X_train, y_train\n",
    "# )\n",
    "\n",
    "sentence_list = citation_stemmed_tokens\n",
    "\n",
    "X_train, X_test, y_train, y_test, athar_train_df, athar_test_df = train_test_split(drop_token_counts_not_in_top(\n",
    "    transform_to_counts(\n",
    "        sentence_list\n",
    "    ), 2000\n",
    "), y_all, athar_df, shuffle=True, test_size=0.5, stratify=None)\n",
    "\n",
    "# X_train_sampled, y_train_sampled = imblearn.over_sampling.RandomOverSampler().fit_sample(\n",
    "#     X_train, y_train\n",
    "# )\n",
    "\n",
    "X_train_sampled, y_train_sampled = imblearn.under_sampling.RandomUnderSampler().fit_sample(\n",
    "    X_train, y_train\n",
    ")\n",
    "\n",
    "X_test_sampled, y_test_sampled, X_test_sampled_indices = imblearn.under_sampling.RandomUnderSampler(\n",
    "    return_indices=True\n",
    ").fit_sample(X_test, y_test)\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(X_train_sampled, y_train_sampled)\n",
    "y_pred = model.predict(X_test_sampled)\n",
    "f1_score(y_test_sampled, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(X_test_sampled)\n",
    "y_incorrect_mask = y_pred != y_test_sampled\n",
    "athar_test_sampled_df = athar_test_df.iloc[X_test_sampled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Wrongly classified as non-negative\n",
       "\n",
       " > **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.81265585 0.18734415])**: For example, 10 million words of the American National Corpus (Ide et al. , 2002) will have manually corrected POS tags, a tenfold increase over the Penn Treebank (Marcus et al. , 1993), currently used for training POS taggers.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.94784872 0.05215128])**: While both (Johnson, 2001) and (Klein and Manning, 2002) propose models which use the parameters of the generative model but train to optimize a discriminative criteria, neither proposes training algorithms which are computationally tractable enough to be used for broad coverage parsing.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.79475429 0.20524571])**: The size of the development set used to generate 1 and 2 (1000 sentences) compensates the tendency of the unsmoothed MERT algorithm to overfit (Och, 2003) by providing a high ratio between number of variables and number of parameters to be estimated.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.80222276 0.19777724])**: 2This can explain why previous attempts to use WordNet for generating sentence-level paraphrases (Barzilay and Lee, 2003; Quirk et al. , 2004) were unsuccessful.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.84228409 0.15771591])**: String alignment with synchronous grammars is quite expensive even for simple synchronous formalisms like ITG (Wu, 1997)but Duchi et al.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.57259307 0.42740693])**: 2 2.1 Word Alignment Adaptation Bi-directional Word Alignment In statistical translation models (Brown et al. , 1993), only one-to-one and more-to-one word alignment links can be found.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.68283011 0.31716989])**: Despite ME theory and its related training algorithm (Darroch and Ratcliff, 1972) do not set restrictions on the range of feature functions1, popular NLP text books (Manning and Schutze, 1999) and research papers (Berger et al. , 1996) seem to limit them to binary features.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.99085268 0.00914732])**: Hanks and Church (1990) proposed using pointwise mutual information to identify collocations in lexicography; however, the method may result in unacceptable collocations for low-count pairs.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.89998442 0.10001558])**: Point-wise mutual information (PMI) is commonly used for computing the association of two terms (e.g., Turney 2002), which is defined as: nullnullnull null null,null null nullnullnull nullnullnullnull,nullnull nullnull null null null nullnullnullnullnull . However, we argue that PMI is not a suitable measure for our purpose.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.71942301 0.28057699])**: Although, there are various manual/automatic evaluation methods for these systems, e.g., BLEU (Papineni et al. 2002), these methods are basically incapable of dealing with an MTsystem and a w/p-MT-system at the same time, as they have different output forms.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.53537149 0.46462851])**: While SCL has been successfully applied to PoS tagging and Sentiment Analysis (Blitzer et al., 2006; Blitzer et al., 2007), its effectiveness for parsing was rather unexplored.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.63959967 0.36040033])**: The program takes the output of char_align (Church, 1993), a robust alternative to sentence-based alignment programs, and applies word-level constraints using a version of Brown el al.'s Model 2 (Brown et al. , 1993), modified and extended to deal with robustness issues.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.99327606 0.00672394])**: Unlike Church and Hanks (1990), Smadja (1993) goes beyond the \"two-word\" limitation and deals with \"collocations of arbitrary length\".\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.7768653 0.2231347])**: Though taggers based on dependency networks (Toutanova et al. , 2003), SVM (Gimenez and M`arquez, 2003), MaxEnt (Ratnaparkhi, 1996), CRF (Smith et al. , 2005), and other methods may reach slightly better results, their train/test cycle is orders of magnitude longer.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [9.99893023e-01 1.06977080e-04])**: In the thriving area of research on automatic analysis and processing of product reviews (Hu and Liu 2004; Turney 2002; Pang and Lee 2005), little attention has been paid to the important task studied here  assessing review helpfulness.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.78456966 0.21543034])**: Our system improves over the latent named-entity tagging in Haghighi and Klein (2007), from 61% to 87%.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.80515402 0.19484598])**: three models in (Collins, 1997) are susceptible to the O(n 3) method (cf.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.67120133 0.32879867])**: In addition, the clustering methods used, such as HMMs and Browns algorithm (Brown et al., 1992), seem unable to adequately capture the semantics of MNs since they are based only on the information of adjacent words.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.51522833 0.48477167])**: Unfortunately, this is not the case for such widely used MT evaluation metrics as BLEU (Papineni et al. , 2002) and NIST (Doddington, 2002).\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.52726732 0.47273268])**: We want to note that our WordNetbased method outperforms that of Hughes and Ramage (2007), which uses a similar method.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.9598111 0.0401889])**: Many approaches for POS tagging have been developed in the past, including rule-based tagging (Brill, 1995), HMM taggers (Brants, 2000; Cutting and others, 1992), maximum-entropy models (Rathnaparki, 1996), cyclic dependency networks (Toutanova et al. , 2003), memory-based learning (Daelemans et al. , 1996), etc. All of these approaches require either a large amount of annotated training data (for supervised tagging) or a lexicon listing all possible tags for each word (for unsupervised tagging).\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [9.99537844e-01 4.62156400e-04])**: 2 Previous work on Sentiment Analysis Some prior studies on sentiment analysis focused on the document-level classification of sentiment (Turney, 2002; Pang et al. , 2002) where a document is assumed to have only a single sentiment, thus these studies are not applicable to our goal.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.52396767 0.47603233])**: As one can see in Table 4, the resulting parser ranks among the best lexicalized parsers, beating those of Collins (1999) and Charniak and Johnson (2005).8 Its F1 performance is a 27% reduction in error over Matsuzaki et al.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.91091138 0.08908862])**: a time-consuming process (Litman and Pan, 2002; Marcus et al. , 1993; Xia et al. , 2000; Wiebe, 2002).\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.76387747 0.23612253])**: Experiments, by using 4 algorithms and through visualization techniques, revealed that clustering is a worthless effort for paraphrase corpora construction, contrary to the literature claims (Barzilay & Lee, 2003).\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.83552395 0.16447605])**: Thirdly, (Shen et al., 2008) deploys the dependency language model to augment the lexical language model probability be1183 tween two head words but never seek a full dependency graph.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.50263089 0.49736911])**: 13Huang and Chiang (2007) give an informal example, but do not elaborate on it.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.82738147 0.17261853])**: Secondly, while most pronoun resolution evaluations simply exclude non-referential pronouns, recent unsupervised approaches (Cherry and Bergsma, 2005; Haghighi and Klein, 2007) must deal with all pronouns in unrestricted text, and therefore need robust modules to automatically handle non-referential instances.\n",
       "\n",
       "> **(sentiment: n, y_test: True, y_pred: False, y_proba: [0.98595971 0.01404029])**: Some are the result of inconsistency in labeling in the training data (Ratnaparkhi 1996), which usually reflects a lack of linguistic clarity or determination of the correct part of speech in context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_sentence_results(mask, title):\n",
    "    df = athar_test_sampled_df[mask]\n",
    "    printmd('## %s\\n\\n %s' % (title, '\\n\\n'.join(\n",
    "        '> **(sentiment: %s, y_test: %s, y_pred: %s, y_proba: %s)**: %s' % (\n",
    "            sentiment, _y_test, _y_pred, _y_proba, s\n",
    "        )\n",
    "        for s, sentiment, _y_test, _y_pred, _y_proba in zip(\n",
    "            df['citation_text'], df['sentiment'], y_test_sampled[mask], y_pred[mask], y_pred_proba[mask]\n",
    "        )\n",
    "    )))\n",
    "\n",
    "show_sentence_results(y_incorrect_mask & (~y_pred), \"Wrongly classified as non-negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Wrongly classified as negative\n",
       "\n",
       " > **(sentiment: o, y_test: False, y_pred: True, y_proba: [2.26526774e-05 9.99977347e-01])**: 1 Introduction With the introduction of the BLEU metric for machine translation evaluation (Papineni et al, 2002), the advantages of doing automatic evaluation for various NLP applications have become increasingly appreciated: they allow for faster implement-evaluate cycles (by by-passing the human evaluation bottleneck), less variation in evaluation performance due to errors in human assessor judgment, and, not least, the possibility of hill-climbing on such metrics in order to improve system performance (Och 2003).\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.4697319 0.5302681])**: For example, Och (2003) shows how to train a log-linear translation model not by maximizing the likelihood of training data, but maximizing the BLEU score (among other metrics) of the model on 53 the data.\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.05859391 0.94140609])**: We use these tuples to calculate a balanced f-score against the gold alignment tuples.4 Method Dict size f-score Gold 28 100.0 Monotone 39 68.9 IBM-1 (Brown et al., 1993) 30 80.3 IBM-4 (Brown et al., 1993) 29 86.9 IP 28 95.9 The last line shows an average f-score over the 8 tied IP solutions.\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.00255489 0.99744511])**: But it makes obvious that (Ratnaparkhi et al. , 1994) were tackling a problem different from (Hindle and Rooth, 1993) given the fact that their baseline was at 59% guessing noun attachment (rather than 67% in the Hindle and Rooth experiments).3 Of course, the baseline is not a direct indicator of the difficulty of the disambiguation task.\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.00207783 0.99792217])**: 2.2 Motivation from previous work 2.2.1 Parsing In recent years, the success of statistical parsing techniques can be attributed to several factors, such as the increasing size of computing machinery to accommodate larger models, the availability of resources such as the Penn Treebank (Marcus et al. , 1993) and the success of machine learning techniques for lowerlevel NLP problems, such as part-of-speech tagging (Church, 1988; Brill, 1995), and PPattachment (Brill and Resnik, 1994; Collins and Brooks, 1995).\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.06248496 0.93751504])**: This conclusion is supported by the fact that true IMT is not, to our knowledge, used in most modern translator's support environments, eg (Eurolang, 1995; I,'rederking et al. , 1993; IBM, 1995; Kugler et al. , 1991; Nirenburg, 1992; ~li'ados, 1995).\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.05155851 0.94844149])**: The word alignment used in GHKM is usually computed independent ofthesyntacticstructure,andasDeNeroandKlein (2007) and May and Knight (2007) have noted, Ch-En En-Ch Union Heuristic 28.6% 33.0% 45.9% 20.1% Table 1: Percentage of corpus used to generate big templates, based on different word alignments 9-12 13-20 21 Ch-En 18.2% 17.4% 64.4% En-Ch 15.9% 20.7% 63.4% Union 9.8% 15.1% 75.1% Heuristic 24.6% 27.9% 47.5% Table 2: In the selected big templates, the distribution of words in the templates of different sizes, which are measured based on the number of symbols in their RHSs is not the best for SSMT systems.\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.05235738 0.94764262])**: 2 The IBM Model 4 For the work described in this paper we used a modified version of the statistical machine translation tool developed in the context of the 1999 Johns HopkinsSummer Workshop (Al-Onaizan et al. , 1999), which implements IBM translation model 4 (Brown et al. , 1993).\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.1137113 0.8862887])**: (Brown et al. , 1993) introduced five statistical translation models (IBM Models 1  5).\n",
       "\n",
       "> **(sentiment: p, y_test: False, y_pred: True, y_proba: [0.0099606 0.9900394])**: In particular, we have implemented an unsupervised morphological analyzer that outperforms Goldsmith s (2001) Linguistica and Creutz and Lagus s (2005) Morfessor for our English and Bengali datasets and compares favorably to the bestperforming morphological parsers in MorphoChallenge 20053 (see Dasgupta and Ng (2007)).\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.03591034 0.96408966])**: Expectation Maximization does surprisingly well on larger data sets and is competitive with the Bayesian estimators at least in terms of cross-validation accuracy, confirming the results reported by Johnson (2007).\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.10132082 0.89867918])**: Furthermore, I plan to apply my parsers in other domains (e.g. , biomedical data) (Blitzer et al. , 2006) besides treebank data, to investigate the effectiveness and generality of my approaches.\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.34067845 0.65932155])**: The trends are the same as in (McClosky et al. , 2006): Adding NANC data improves parsing performance on BROWN development considerably, improving the f-score from 83.9% to 86.4%.\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.43618611 0.56381389])**: Some of the alignment sets also have links which are not Sure links but are Possible links (Och and Ney 2003).\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.00384115 0.99615885])**: Our experimental results display that our SDB model achieves a substantial improvement over the baseline and significantly outperforms XP+ according to the BLEU metric (Papineni et al., 2002).\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.49058412 0.50941588])**: 2 Background: Overview of BLEU This section briefly describes the original BLEU (Papineni et al. , 2002b)1, which was designed for English translation evaluation, so English sentences are used as examples in this section.\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.03813847 0.96186153])**: But because we want the insertion state a1a16a20 to model digressions or unseen topics, we take the novel step of forcing its language model to be complementary to those of the other states by setting a2 a3a27a38 a21 a8 a8 a4 a8 a24 a26a11a28a30a29a6 a39a41a40a43a42a45a44a16a46 a1a48a47a1a50a49 a20 a2 a3 a26a17a21 a8a9a8 a4 a8 a24 a51a53a52a55a54a57a56 a21 a39a58a40a43a42a45a44a16a46 a1a59a47a1a50a49 a20 a2 a3a27a26a11a21a50a60 a4 a8 a24a30a24 a17 4Following Barzilay and Lee (2003), proper names, numbers and dates are (temporarily) replaced with generic tokens to help ensure that clusters contain sentences describing the same event type, rather than same actual event.\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.18880003 0.81119997])**: (2003), a trigram target language model, an order model, word count, phrase count, average phrase size functions, and whole-sentence IBM Model 1 logprobabilities in both directions (Och et al. 2004).\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.18875035 0.81124965])**: Whereas Ratnaparkhi (1996) used feature support cutoffs and early stopping to stop overfitting of the model, and Collins (2002) contends that including low support features harms a maximum entropy model, our results show that low support features are useful in a regularized maximum entropy model.\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.49677433 0.50322567])**: Following previous work in statistical MT (Brown et al., 1993), we envision a noisy-channel model in which a language model generates English, and then a translation model transforms English trees into Chinese.\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.18634208 0.81365792])**: Dialogs Speakers Turns Words Fragments Distinct Words Distinct Words/POS Singleton Words Singleton Words/POS Intonational Phrases Speech Repairs 98 34 6163 58298 756 859 1101 252 350 10947 2396 Table 1: Size of the Trains Corpus 2.1 POS Annotations Our POS tagset is based on the Penn Treebank tagset (Marcus et al. , 1993), but modified to include tags for discourse markers and end-of-turns, and to provide richer syntactic information (Heeman, 1997).\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.29114584 0.70885416])**: First, we need to determine whether or not the positive effect of SVD feature selection is preserved in more complex feature spaces such as syntactic feature spaces as those used in (Snow et al., 2006).\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.34502358 0.65497642])**: These joint counts are estimated using the phrase induction algorithm described in (Koehn et al. , 2003), with symmetrized word alignments generated using IBM model 2 (Brown et al. , 1993).\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.01502846 0.98497154])**: (1997), Johnson (1998)--that conditioning the probabilities of structures on the context within which they appear, for example on the lexical head of a constituent (Charniak 1997; Collins 1997), on the label of its parent nonterrninal (Johnson 1998), or, ideally, on both and many other things besides, leads to a much better parsing model and results in higher parsing accuracies.\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.49836264 0.50163736])**: Some existing resources contain lists of subjective words (e.g. , Levins desire verbs (1993)), and some empirical methods in NLP have automatically identified adjectives, verbs, and N-grams that are statistically associated with subjective language (e.g. , (Turney, 2002; Hatzivassiloglou and McKeown, 1997; Wiebe, 2000; Wiebe et al. , 2001)).\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.30084391 0.69915609])**: 8This result is presented as 0.053 with the official ROUGE scorer (Lin, 2004).\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.48103389 0.51896611])**: Wu (1997)s Inversion Transduction Grammar, as well as tree-transformation models of translation such as Yamada and Knight (2001), Galley et al.\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.23058278 0.76941722])**: In many cases, improving semi-supervised models was done by seeding these models with domain information taken from dictionaries or ontology (Cohen and Sarawagi, 2004; Collins and Singer, 1999; Haghighi and Klein, 2006; Thelen and Riloff, 2002).\n",
       "\n",
       "> **(sentiment: o, y_test: False, y_pred: True, y_proba: [0.27900263 0.72099737])**: Therefore, other machine learning techniques such as perceptron (Collins, 2002) could also be applied for this problem."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_sentence_results(y_incorrect_mask & (y_pred), \"Wrongly classified as negative\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
