{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import imblearn.under_sampling\n",
    "import imblearn.over_sampling\n",
    "import imblearn.pipeline\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from citation_sentiment_analysis.datasets.athar import (\n",
    "    download_and_read_athar_txt_with_sentiment_label,\n",
    "    filter_long_sentences_from_athar\n",
    ")\n",
    "from citation_sentiment_analysis.preprocessing.token_filter import (\n",
    "    get_default_words_to_include,\n",
    "    keep_sentence_list_tokens_in\n",
    ")\n",
    "from citation_sentiment_analysis.utils.plot import configure_default_plot_style\n",
    "from citation_sentiment_analysis.utils.vectorizer import transform_to_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "configure_default_plot_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_paper_id</th>\n",
       "      <th>target_paper_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>citation_text</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1043</td>\n",
       "      <td>A00-2024</td>\n",
       "      <td>o</td>\n",
       "      <td>We analyzed a set of articles and identified s...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H05-1033</td>\n",
       "      <td>A00-2024</td>\n",
       "      <td>o</td>\n",
       "      <td>Table 3: Example compressions Compression AvgL...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I05-2009</td>\n",
       "      <td>A00-2024</td>\n",
       "      <td>o</td>\n",
       "      <td>5.3 Related works and discussion Our two-step ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I05-2009</td>\n",
       "      <td>A00-2024</td>\n",
       "      <td>o</td>\n",
       "      <td>(1999) proposed a summarization system based o...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I05-2009</td>\n",
       "      <td>A00-2024</td>\n",
       "      <td>o</td>\n",
       "      <td>We found that the deletion of lead parts did n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_paper_id target_paper_id sentiment  \\\n",
       "0        A00-1043        A00-2024         o   \n",
       "1        H05-1033        A00-2024         o   \n",
       "2        I05-2009        A00-2024         o   \n",
       "3        I05-2009        A00-2024         o   \n",
       "4        I05-2009        A00-2024         o   \n",
       "\n",
       "                                       citation_text sentiment_label  \n",
       "0  We analyzed a set of articles and identified s...         neutral  \n",
       "1  Table 3: Example compressions Compression AvgL...         neutral  \n",
       "2  5.3 Related works and discussion Our two-step ...         neutral  \n",
       "3  (1999) proposed a summarization system based o...         neutral  \n",
       "4  We found that the deletion of lead parts did n...         neutral  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "athar_df = filter_long_sentences_from_athar(download_and_read_athar_txt_with_sentiment_label())\n",
    "athar_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109442"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_include = get_default_words_to_include()\n",
    "\n",
    "len(words_to_include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tokens: 384256, unique: 19323\n",
      "['We', 'analyzed', 'a', 'set', 'of', 'articles', 'and', 'identified', 'six', 'major', 'operations', 'that', 'can', 'be', 'used', 'for', 'editing', 'the', 'extracted', 'sentences']\n"
     ]
    }
   ],
   "source": [
    "citation_texts = athar_df['citation_text']\n",
    "\n",
    "citation_tokens = [nltk.word_tokenize(s) for s in citation_texts]\n",
    "print('total tokens: %d, unique: %d' % (\n",
    "    sum(len(tokens) for tokens in citation_tokens),\n",
    "    len({t for tokens in citation_tokens for t in tokens})\n",
    "))\n",
    "print(citation_tokens[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tokens: 169508, unique: 6205\n",
      "['analyzed', 'set', 'articles', 'and', 'identified', 'six', 'major', 'operations', 'that', 'can', 'used', 'for', 'editing', 'the', 'extracted', 'sentences', 'including', 'removing', 'extraneous', 'phrases']\n"
     ]
    }
   ],
   "source": [
    "citation_filtered_tokens = keep_sentence_list_tokens_in(citation_tokens, words_to_include)\n",
    "print('total tokens: %d, unique: %d' % (\n",
    "    sum(len(tokens) for tokens in citation_filtered_tokens),\n",
    "    len({t for tokens in citation_filtered_tokens for t in tokens})\n",
    "))\n",
    "print(citation_filtered_tokens[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['analyz', 'set', 'articl', 'and', 'identifi', 'six', 'major', 'oper', 'that', 'can', 'use', 'for', 'edit', 'the', 'extract', 'sentenc', 'includ', 'remov', 'extran', 'phrase']\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "citation_stemmed_tokens = [[ps.stem(t) for t in tokens] for tokens in citation_filtered_tokens]\n",
    "print(citation_stemmed_tokens[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8699, 3617)\n",
      "(8699,)\n"
     ]
    }
   ],
   "source": [
    "X_all = transform_to_counts(citation_stemmed_tokens)\n",
    "y_all = athar_df['sentiment'] == 'n'\n",
    "\n",
    "print(X_all.shape)\n",
    "print(y_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc mean: 0.770593509736653, std: 0.0432709152384011\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(\n",
    "    BernoulliNB(), X_all, y_all, cv=4, scoring='roc_auc'\n",
    ")\n",
    "print('roc_auc mean: %s, std: %s' % (scores.mean(), scores.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
